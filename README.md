# LLM_falcon-7b-instruct_on_local

Run LLM model, falcon-7b-instruct on Google Colab, HuggingFace Spaces and Local if you have 16GB GPU.  

---

Huge thanks to Nicholas Renotte - Main Code from here: [GitHub - nicknochnack/Falcon40B](https://github.com/nicknochnack/Falcon40B) 

- [My falcon-7b-instruct HuggingFaceðŸ¤— Space App](https://huggingface.co/spaces/ahmetekiz/LLM_falcon7b)
- falcon-7b-instruct Notebook - [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lrgZdBUTueIJOaEe3hXmUWWvQbGArcY3)
- falcon-7b-instruct with Memory Module -  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1g8n91w-qeLPajLF6mVbszykNduXf1uNf)

---

# Useful Resources

- Deploy LLM Chat Models in 2 min on HuggingFace from [Merve Noyan](https://www.linkedin.com/posts/merve-noyan-28b1a113a_deploy-your-own-llama-v2-in-2-minutes-activity-7088090952774356992-AifR?utm_source=share&utm_medium=member_desktop):
  -  [Try LLaMA v2 on HuggingFace](https://huggingface.co/spaces/merve/my-own-llama-v2)
  -  [Tutorial: How to deploy your chatui on HuggingFace](https://huggingface.co/docs/hub/spaces-sdks-docker-chatui#chatui-on-spaces)
  -  [Start to build your chatui on HuggingFace](https://huggingface.co/new-space?template=huggingchat/chat-ui-template)



# Resources

- [GitHub - nicknochnack/Falcon40B](https://github.com/nicknochnack/Falcon40B)
